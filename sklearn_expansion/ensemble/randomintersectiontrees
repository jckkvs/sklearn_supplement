from sklearn.base import BaseEstimator, RegressorMixin
import numpy as np
import random

class RandomIntersectionTreeRegressor(BaseEstimator, RegressorMixin):
    def __init__(self, max_depth=5, branching_factor=5, random_state=None):
        self.max_depth = max_depth
        self.branching_factor = branching_factor
        self.random_state = random_state
        self.tree = {}
    
    def fit(self, X, y, sample_weight=None):
        if self.random_state is not None:
            random.seed(self.random_state)
        if sample_weight is None:
            sample_weight = np.ones(len(y))
        self._build_tree(X, y, sample_weight, depth=0, node_id=0)
        return self
    
    def _build_tree(self, X, y, sample_weight, depth, node_id):
        if depth >= self.max_depth:
            return
        n_samples, n_features = X.shape
        selected_samples = random.sample(range(n_samples), min(self.branching_factor, n_samples))
        
        # Create a hash table to store the intersection results
        hash_table = {}
        for sample in selected_samples:
            hash_val = tuple(X[sample, :])
            if hash_val in hash_table:
                hash_table[hash_val].append((y[sample], sample_weight[sample]))
            else:
                hash_table[hash_val] = [(y[sample], sample_weight[sample])]
        
        # Store the hash table at the current node
        self.tree[node_id] = hash_table
        
        # Recursively build child nodes
        next_node_id = node_id + 1
        for hash_val, labels_weights in hash_table.items():
            child_X = np.array([X[i, :] for i, x in enumerate(X) if all(x == np.array(hash_val))])
            child_y = np.array([y[i] for i, x in enumerate(X) if all(x == np.array(hash_val))])
            child_sample_weight = np.array([sample_weight[i] for i, x in enumerate(X) if all(x == np.array(hash_val))])
            self._build_tree(child_X, child_y, child_sample_weight, depth + 1, next_node_id)
            next_node_id += 1
            
    def predict(self, X):
        n_samples = X.shape[0]
        predictions = np.zeros(n_samples)
        for i in range(n_samples):
            all_labels_weights = self._query_tree(X[i, :], node_id=0)
            if len(all_labels_weights) == 0:
                predictions[i] = 0
            else:
                labels, weights = zip(*all_labels_weights)
                predictions[i] = np.average(labels, weights=weights)
        return predictions
    
    def _query_tree(self, X, node_id):
        if node_id not in self.tree:
            return []
        hash_val = tuple(X)
        if hash_val not in self.tree[node_id]:
            return []
        labels_weights = self.tree[node_id][hash_val]
        next_node_id = node_id + 1
        for _ in self.tree[node_id].keys():
            labels_weights.extend(self._query_tree(X, next_node_id))
            next_node_id += 1
        return labels_weights

# RandomIntersectionTrees クラスの定義
class RandomIntersectionTreesRegressor(BaseEstimator, RegressorMixin):
    def __init__(self, n_estimators=10, max_depth=5, branching_factor=5, random_state=None):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.branching_factor = branching_factor
        self.random_state = random_state
        self.trees = []
        
    def fit(self, X, y, sample_weight=None):
        for i in range(self.n_estimators):
            tree = RandomIntersectionTreeRegressor(max_depth=self.max_depth, branching_factor=self.branching_factor, random_state=self.random_state)
            tree.fit(X, y, sample_weight=sample_weight)
            self.trees.append(tree)
        return self
    
    def predict(self, X):
        n_samples = X.shape[0]
        predictions = np.zeros(n_samples)
        for tree in self.trees:
            predictions += tree.predict(X)
        return predictions / self.n_estimators
from sklearn.base import BaseEstimator, ClassifierMixin
import numpy as np
import random

from sklearn.base import BaseEstimator, ClassifierMixin

class RandomIntersectionTreeClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, max_depth=5, branching_factor=5):
        self.max_depth = max_depth
        self.branching_factor = branching_factor
        self.tree = {}
    
    def fit(self, X, y, sample_weight=None, random_state=None):
        if random_state:
            random.seed(random_state)
        if sample_weight is None:
            sample_weight = np.ones(len(y))
        self._build_tree(X, y, sample_weight, depth=0, node_id=0)
    
    def _build_tree(self, X, y, sample_weight, depth, node_id):
        if depth >= self.max_depth:
            return
        n_samples, n_features = X.shape
        selected_samples = random.sample(range(n_samples), min(self.branching_factor, n_samples))
        
        # Create a hash table to store the intersection results
        hash_table = {}
        for sample in selected_samples:
            hash_val = tuple(X[sample, :])
            if hash_val in hash_table:
                hash_table[hash_val].append((y[sample], sample_weight[sample]))
            else:
                hash_table[hash_val] = [(y[sample], sample_weight[sample])]
        
        # Store the hash table at the current node
        self.tree[node_id] = hash_table
        
        # Recursively build child nodes
        next_node_id = node_id + 1
        for hash_val, label_weights in hash_table.items():
            child_X = np.array([X[i, :] for i, x in enumerate(X) if all(x == np.array(hash_val))])
            child_y = np.array([y[i] for i, x in enumerate(X) if all(x == np.array(hash_val))])
            child_sample_weight = np.array([sample_weight[i] for i, x in enumerate(X) if all(x == np.array(hash_val))])
            self._build_tree(child_X, child_y, child_sample_weight, depth + 1, next_node_id)
            next_node_id += 1
            
    def query(self, X):
        return self._query_tree(X, node_id=0)
    
    def _query_tree(self, X, node_id):
        if node_id not in self.tree:
            return []
        hash_val = tuple(X)
        if hash_val not in self.tree[node_id]:
            return []
        label_weights = self.tree[node_id][hash_val]
        next_node_id = node_id + 1
        for _ in self.tree[node_id].keys():
            label_weights.extend(self._query_tree(X, next_node_id))
            next_node_id += 1
        return label_weights

class RandomIntersectionTreesClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, n_estimators=10, max_depth=5, branching_factor=5):
        self.n_estimators = n_estimators
        self.max_depth = max_depth
        self.branching_factor = branching_factor
        self.trees = []
        
    def fit(self, X, y, sample_weight=None):
        for i in range(self.n_estimators):
            tree = RandomIntersectionTreeClassifier(max_depth=self.max_depth, branching_factor=self.branching_factor)
            tree.fit(X, y, sample_weight)
            self.trees.append(tree)
    
    def predict(self, X):
        n_samples = X.shape[0]
        predictions = np.zeros(n_samples)
        for i in range(n_samples):
            all_labels = []
            all_weights = []
            for tree in self.trees:
                label_weights = tree.query(X[i, :])
                labels, weights = zip(*label_weights)
                all_labels.extend(labels)
                all_weights.extend(weights)
            
            if len(all_labels) == 0:
                predictions[i] = 0
            else:
                # Weighted mean of labels
                predictions[i] = np.average(all_labels, weights=all_weights)
        return predictions
